{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8beed94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicor\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from trainertf_mod import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49205daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data import\n",
    "data_path_p= \"./data/ben\"\n",
    "data_path_a= \"./data/bena\"\n",
    "data_path_n= \"./data/celeb2\"\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1327dd2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4820\\711735133.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#reshape if not thsi size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#randomize order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       raise ValueError(\n\u001b[1;32m--> 145\u001b[1;33m           \u001b[1;34m'`labels` argument should be a list/tuple of integer labels, of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m           \u001b[1;34m'the same size as the number of image files in the target '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m           \u001b[1;34m'directory. If you wish to infer the labels from the subdirectory '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`."
     ]
    }
   ],
   "source": [
    "ds_pos = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path_p,\n",
    "    labels=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width), #reshape if not thsi size\n",
    "    shuffle=True, #randomize order\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7042a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4820\\2371668042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#reshape if not thsi size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#randomize order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       raise ValueError(\n\u001b[1;32m--> 145\u001b[1;33m           \u001b[1;34m'`labels` argument should be a list/tuple of integer labels, of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m           \u001b[1;34m'the same size as the number of image files in the target '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m           \u001b[1;34m'directory. If you wish to infer the labels from the subdirectory '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=\"inferred\"`. If you wish to get a dataset that only contains images (no labels), pass `label_mode=None`."
     ]
    }
   ],
   "source": [
    "ds_anc = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path_a,\n",
    "    labels=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width), #reshape if not thsi size\n",
    "    shuffle=True, #randomize order\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "ds_neg = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path_n,\n",
    "    labels=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width), #reshape if not thsi size\n",
    "    shuffle=True, #randomize order\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1474fec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4820\\475638253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mds_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image --> '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds_pos' is not defined"
     ]
    }
   ],
   "source": [
    "def preproc(img):\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    #img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    #img = img[None, ...]\n",
    "    print(img)\n",
    "    return img\n",
    "ds_p = ds_pos.map(preproc)\n",
    "for x in ds_p.take(1):\n",
    "    print('Image --> ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e732d0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resize/ResizeBilinear:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
      "<ShuffleDataset shapes: ((None, 224, 224, 3), (None, 224, 224, 3), (None, 224, 224, 3)), types: (tf.float32, tf.float32, tf.float32)>\n",
      "epoch 0:\n",
      "epoch 1:\n",
      "epoch 2:\n"
     ]
    }
   ],
   "source": [
    "ds_n = ds_neg.map(preproc)\n",
    "dataset = tf.data.Dataset.zip((ds_p, ds_p, ds_n))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "print(dataset)\n",
    "for epoch in range(3):\n",
    "    print(f'epoch {epoch}:')\n",
    "    for step, X in enumerate(dataset):\n",
    "        a , p , n = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6c75ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image -->  (256, 256, 3) Label -->  (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds_anc.take(1):\n",
    "    print('Image --> ', x.shape, 'Label --> ',  y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1eec741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    \n",
    "    def metrics(self, L, X, Y_pred, Y_true):\n",
    "        Y_pred_ndx = tf.argmax(Y_pred, axis=-1)\n",
    "        acc = 0\n",
    "        #acc = tf.reduce_mean(tf.cast(Y_pred_ndx == Y_true, tf.float32))\n",
    "        return {'loss': L, 'acc': acc}\n",
    "\n",
    "    def train_report(self, epoch, step):\n",
    "        print(f\"    {epoch:03d}/{step:05d}:  loss {self.loss:6.4f}, acc (avg) {self.avg_acc:6.4f}\")\n",
    "\n",
    "    def test_report(self, epoch, step):\n",
    "        print('-' * 50)\n",
    "        print(f\"> {epoch:03d}/{step + 1:05d}:  loss {self.test_loss:6.4f}, acc {self.test_acc:6.4f}\")\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1a4fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_shape = (224,224,3)             \n",
    "        self.mnet_mdl = tf.keras.applications.MobileNetV2(input_shape=self.in_shape, include_top=False, weights='imagenet')\n",
    "        for l in self.mnet_mdl.layers[:144]:\n",
    "            l.trainable=False\n",
    "        for l in self.mnet_mdl.layers[144:]:\n",
    "            l.trainable=True\n",
    "            \n",
    "        self.global_ap = layers.GlobalAveragePooling2D()\n",
    "        \n",
    "        #--> maybe more layers needed for embedding\n",
    "        #self.dense1 = layers.Dense(512, activation=\"relu\")\n",
    "        #self.norm1 = layers.BatchNormalization()\n",
    "\n",
    "        # Create embeddings with Batch Normalization or Layer Normalization \n",
    "        self.dense1 = layers.Dense(256, activation=\"relu\")\n",
    "        self.norm1 = layers.BatchNormalization()\n",
    "        self.dense2 = layers.Dense(256, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x0, training=False):\n",
    "        x1 = self.mnet_mdl(x0)\n",
    "        x2 = self.global_ap(x1)\n",
    "        x3 = self.dense1(x2)\n",
    "        x4 = self.norm1(x3)\n",
    "        x5 = self.dense2(x4)\n",
    "        return x5\n",
    "    \n",
    "    def sample_loss_fn(self, X, Y_true, Y_pred):\n",
    "        single_squared_loss = tf.square(Y_pred)\n",
    "        return tf.reduce_sum(single_squared_loss)\n",
    "\n",
    "    def loss_fn(self, X, Y_true, Y_pred):\n",
    "        return tf.reduce_mean(self.sample_loss_fn(X, Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5d24b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 train samples.\n",
      "Model: \"embedding_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 2,652,736\n",
      "Trainable params: 1,126,720\n",
      "Non-trainable params: 1,526,016\n",
      "_________________________________________________________________\n",
      "epoch 0:\n",
      "    000/00000:  loss 0.0134, acc (avg) 0.0000\n",
      "epoch 1:\n",
      "    001/00000:  loss 0.0146, acc (avg) 0.0000\n",
      "epoch 2:\n",
      "    002/00000:  loss 0.0120, acc (avg) 0.0000\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'n_epochs':     3, \n",
    "    'batch_size':   batch_size, \n",
    "    'opt':          tf.optimizers.Adam(learning_rate=0.001),\n",
    "    'train_ds':     ds_p,   \n",
    "    'test_ds':      None,\n",
    "}\n",
    "\n",
    "model1 = Embedding()\n",
    "tr = MyTrainer(model1, cfg)\n",
    "model1.summary()\n",
    "hist = tr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c7db416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLayer(layers.Layer):\n",
    "    def __init__(self, alph=0.5):\n",
    "        super(TripletLayer, self).__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        anchor,positive,negative = inputs\n",
    "        pos_distance = tf.math.reduce_sum(tf.math.square(anchor - positive), axis=1)\n",
    "        neg_distance = tf.math.reduce_sum(tf.math.square(anchor - negative), axis=1)    \n",
    "        return (pos_distance, neg_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c950bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEmbedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_shape = (256,256,3)\n",
    "        self.embedding = Embedding()\n",
    "        self.triplet_l = TripletLayer()\n",
    "        \n",
    "    def call(self,X):\n",
    "        #Embeddings for positive, anchor and negative\n",
    "        anchor_input , positive_input , negative_input = X\n",
    "        #print(positive_input)\n",
    "        x_p = self.embedding(positive_input)\n",
    "        x_a = self.embedding(anchor_input)\n",
    "        x_n = self.embedding(negative_input)\n",
    "        X_res = x_a , x_p , x_n\n",
    "        #Tripplet loss\n",
    "        x_los = self.triplet_l(X_res)\n",
    "        return x_los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a26ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCompl(tf.keras.Model):\n",
    "    def __init__(self, face_embedding):\n",
    "        super().__init__()\n",
    "        self.face_embeddings_mdl = face_embedding\n",
    "        \n",
    "    def call(self, X):\n",
    "        return self.face_embeddings_mdl(X)\n",
    "    \n",
    "    def sample_loss_fn(self, embeddings):\n",
    "        ap_distance, an_distance = embeddings\n",
    "        loss = ap_distance - an_distance\n",
    "        return loss\n",
    "    \n",
    "    def loss_fn(self, X, Y_true, Y_pred):\n",
    "        return tf.math.reduce_max(self.sample_loss_fn(Y_pred) + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee77bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 train samples.\n",
      "Warning: no in_shape in the model specified. This is ok but the summary command may not work.\n",
      "epoch 0:\n",
      "    000/00000:  loss 0.2021, acc (avg) 0.0000\n",
      "epoch 1:\n",
      "    001/00000:  loss 0.1999, acc (avg) 0.0000\n",
      "epoch 2:\n",
      "    002/00000:  loss 0.1983, acc (avg) 0.0000\n",
      "epoch 3:\n",
      "    003/00000:  loss 0.1984, acc (avg) 0.0000\n",
      "epoch 4:\n",
      "    004/00000:  loss 0.1987, acc (avg) 0.0000\n",
      "epoch 5:\n",
      "    005/00000:  loss 0.1956, acc (avg) 0.0000\n",
      "epoch 6:\n",
      "    006/00000:  loss 0.1934, acc (avg) 0.0000\n",
      "epoch 7:\n",
      "    007/00000:  loss 0.2030, acc (avg) 0.0000\n",
      "epoch 8:\n",
      "    008/00000:  loss 0.1285, acc (avg) 0.0000\n",
      "epoch 9:\n",
      "    009/00000:  loss 0.1342, acc (avg) 0.0000\n",
      "Model: \"model_compl_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "face_embedding_11 (FaceEmbed multiple                  2652736   \n",
      "=================================================================\n",
      "Total params: 2,652,736\n",
      "Trainable params: 1,126,720\n",
      "Non-trainable params: 1,526,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'n_epochs':     10, \n",
    "    'batch_size':   batch_size, \n",
    "    'opt':          tf.optimizers.Adam(learning_rate=0.001),\n",
    "    'train_ds':     dataset,   \n",
    "    'test_ds':      None,\n",
    "}\n",
    "\n",
    "embeding_1 = FaceEmbedding()\n",
    "model_cpl = ModelCompl(embeding_1)\n",
    "tr = MyTrainer(model_cpl, cfg)\n",
    "#model_cpl.compile(tf.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "hst = tr.train()\n",
    "model_cpl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f5d2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEmbedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_shape = (256,256,3)           \n",
    "        self.embedding = Embedding()\n",
    "        self.triplet_l = TripletLayer()\n",
    "\n",
    "    def call(self,X):\n",
    "        #Embeddings for positive, anchor and negative\n",
    "        anchor_input , positive_input , negative_input = X\n",
    "        x_p = self.embedding(positive_input)\n",
    "        x_a = self.embedding(anchor_input)\n",
    "        x_n = self.embedding(negative_input)\n",
    "        X_res = x_a , x_p , x_n\n",
    "        #Tripplet loss\n",
    "        x_los = self.triplet_l(X_res)\n",
    "        return x_los\n",
    "    \n",
    "    def sample_loss_fn(self, embeddings):\n",
    "        ap_distance, an_distance = embeddings\n",
    "        loss = ap_distance - an_distance\n",
    "        return loss\n",
    "    \n",
    "    def loss_fn(self, embeddings):\n",
    "        return tf.math.reduce_max(sample_loss_fn(embeddings) + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1790cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    def metrics(self, L, X, Y_pred, Y_true):\n",
    "        #Y_pred_ndx = tf.argmax(Y_pred, axis=-1)\n",
    "        #acc = tf.reduce_mean(tf.cast(Y_pred_ndx == Y_true, tf.float32))\n",
    "        \n",
    "        return {'loss': L}\n",
    "\n",
    "    def train_report(self, epoch, step):\n",
    "        print(f\"    {epoch:03d}/{step:05d}:  loss {self.loss:6.4f}, acc (avg) {self.avg_acc:6.4f}\")\n",
    "\n",
    "    def test_report(self, epoch, step):\n",
    "        print('-' * 50)\n",
    "        print(f\"> {epoch:03d}/{step + 1:05d}:  loss {self.test_loss:6.4f}, acc {self.test_acc:6.4f}\")\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52da7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "model1 = FaceEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e78684",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_epochs':     3,\n",
    "    'batch_size':   batch_size,\n",
    "    'opt':          tf.optimizers.Adam(learning_rate=0.001),\n",
    "    'train_ds':     dataset,\n",
    "    'test_ds':      dataset,\n",
    "    'report_steps': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6bed8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 train samples.\n",
      "Found 10 test samples.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:443\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mFaceEmbedding.call\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#Embeddings for positive, anchor and negative\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     anchor_input , positive_input , negative_input \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     11\u001b[0m     x_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(positive_input)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:520\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 520\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disallow_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape_tuple()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:516\u001b[0m, in \u001b[0;36mTensor._disallow_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m   \u001b[38;5;66;03m# Default: V1-style Graph execution.\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disallow_in_graph_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miterating over `tf.Tensor`\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:494\u001b[0m, in \u001b[0;36mTensor._disallow_in_graph_mode\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_disallow_in_graph_mode\u001b[39m(\u001b[38;5;28mself\u001b[39m, task):\n\u001b[1;32m--> 494\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOperatorNotAllowedInGraphError(\n\u001b[0;32m    495\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not allowed in Graph execution. Use Eager execution or decorate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this function with @tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(task))\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr \u001b[38;5;241m=\u001b[39m \u001b[43mMyTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model1\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\Documents\\nico\\trainertf.py:158\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, mdl, config)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdl, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdl, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_shape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# needed for a keras summary\u001b[39;00m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdl\u001b[38;5;241m.\u001b[39mcall(layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdl\u001b[38;5;241m.\u001b[39min_shape))\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:445\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    443\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m--> 445\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou cannot build your model by calling `build` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    446\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif your layers do not support float type inputs. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    447\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead, in order to instantiate and build your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    448\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel, `call` your model on real tensor data (of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    449\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe correct dtype).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28msuper\u001b[39m(Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbuild(input_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype)."
     ]
    }
   ],
   "source": [
    "tr = MyTrainer(model1, cfg)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c55197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py7 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
